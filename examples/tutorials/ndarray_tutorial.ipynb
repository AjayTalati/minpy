{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDArray Tutorial\n",
    "\n",
    "## Basic NDArray Operation\n",
    "\n",
    "Minpy has the same syntax with Numpy, which is flexible and familiar. You only need to replace `import numpy as np` with `import minpy.numpy as np` at the header of NumPy program. if you are not familiar with Numpy, you may want to look up [NumPy Quickstart Tutorial](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Evaluation\n",
    "\n",
    "Minpy uses lazy evaluation for better performance. When we run `a=b+1` in python, the python thread just pushs the operation into the backend MXNet engine and then returns. There are two benefits for such optimization:\n",
    "1. The main python thread can continue to execute other computations once the previous one is pushed. It is useful for frontend languages with heavy overheads. \n",
    "2. It is easier for the backend engine to explore further optimization, such as auto parallelization.\n",
    "\n",
    "The backend engine is able to resolve the data dependencies and schedule the computations correctly. It is transparent to frontend users. We can explicitly call the method `asnumpy` that copy result data to numpy array, which will wait the computation finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for all computations are pushed into the backend engine: 0.008766 sec\n",
      "time for all computations are finished: 2.235336 sec\n"
     ]
    }
   ],
   "source": [
    "import minpy.numpy as np\n",
    "import time\n",
    "\n",
    "def do(x, n):\n",
    "    \"\"\"push computation into the backend engine\"\"\"\n",
    "    return [np.dot(x,x) for i in range(n)]\n",
    "def wait(x):\n",
    "    \"\"\"wait until all results are available\"\"\"\n",
    "    for y in x:\n",
    "        y.asnumpy()\n",
    "        \n",
    "tic = time.time()\n",
    "a = np.ones((1000,1000))\n",
    "b = do(a, 50)\n",
    "toc = time.time() - tic\n",
    "print('time for all computations are pushed into the backend engine: %f sec' % (time.time() - tic))\n",
    "wait(b)\n",
    "print('time for all computations are finished: %f sec' % (time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept of transparent fallback\n",
    "\n",
    "Since Minpy fully integrates MXNet, it allows you to use GPU to speed up your algorithm with only mirror change, while keeping the neat NumPy syntax you just went through. However, NumPy is a giant library with hundreds of operators. Our supported GPU operators are only a subset of them, so it is inevitable that you want to try some functions that are currently missing on GPU side. To solve this problem, MinPy gracefully adopts the NumPy implementation once the operator is missing on GPU side, and handles the memory copies among GPU and CPU for you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mI0916 17:21:34 34295 minpy.array:_synchronize_data:412]\u001b[0m Copy from MXNet array to NumPy array for Array \"4513052704\".\n",
      "\u001b[32mI0916 17:21:34 34295 minpy.array:_synchronize_data:418]\u001b[0m Copy from NumPy array to MXNet array for Array \"4513051984\".\n"
     ]
    }
   ],
   "source": [
    "# First turn on the logging to know what happens under the hood.\n",
    "import logging\n",
    "logging.getLogger('minpy.array').setLevel(logging.DEBUG)\n",
    "\n",
    "x = np.zeros((10, 20))\n",
    "\n",
    "# `cosh` is currently missing in MXNet's GPU implementation.\n",
    "# So it will fallback to use NumPy's CPU implementation,\n",
    "# but you don't need to worry about the memory copy from GPU -> CPU\n",
    "y = np.cosh(x)\n",
    "\n",
    "# `log` has GPU implementation, so it will copy the array from CPU -> GPU.\n",
    "# Once again, you don't need to worry about it. It is transparent.\n",
    "z = np.log(y)\n",
    "\n",
    "# Turn off the logging.\n",
    "logging.getLogger('minpy.array').setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitfalls when working together with Numpy\n",
    "\n",
    "Due to the difference between NumPy and MXNet interface, there exist a few of NumPy function cannot work property in the `PreferMXNetPolicy`. We suggest that try to separate the code into two parts. One is for some non-critical codes like data preparation or visualization. Just use numpy in this part. Another is for performance-critical part like loss function or weight update. Use minpy in this part. Besides, you could always switch namespace by `set_global_policy` in any place like:\n",
    "\n",
    "\n",
    "``` python\n",
    "import minpy\n",
    "\n",
    "def strange_func(...):\n",
    "    minpy.set_global_policy(minpy.OnlyNumpyPolicy())\n",
    "    # for some particular code only can run with NumPy...\n",
    "    # pure numpy code\n",
    "    minpy.set_global_policy(minpy.PreferMXNetPolicy())\n",
    "    return x, y\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
